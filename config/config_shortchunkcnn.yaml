# hyperparameters
feature_length: 10
feature_type: log_mel
learning_rate: 0.0001
batch_size: 32
num_epochs: 50

saved_models_count: 0
max_models_saved: 20
save_interval: 5
num_workers: 8

# model architecture
model:
  name: ShortChunkCNN
  sample_rate: 16000
  n_fft: 256
  f_min: 0.0
  f_max: 8000.0
  n_mels: 128
  dropout_rate: 0.5
# dataset
dataset:
  name: mtat
  csv_dir: ../data/magnatagatune/annotations_final_new.csv
  num_classes: 50

# optimizer
optimizer:
  name: AdamW
  lr: 0.0001
  weight_decay: 0.0001

loss:
  type: BCE # BCE / weightedBCE
  weight: fixed # fixed / balanced_cls / balanced_pn / balanced_pn_cls
# trainer
# trainer:
#   gpus: 1
#   checkpoint_callback: True
#   early_stop_callback: True
  